# API Test Scripts

This folder contains automated test scripts for verifying the API endpoints of the OCR Document Extraction Application.

## Prerequisites

Before running the tests, ensure you have the following Python packages installed:

```bash
pip install requests colorama python-dotenv
```

## Running the Tests

### Run All Tests

To run all test scripts at once:

```bash
python run_all_tests.py
```

This will:
- Execute all test files that start with `test_`
- Display the results for each test
- Generate a consolidated report in `test_report.json`

### Run Individual Test Files

You can also run specific test files individually:

```bash
python test_health_routes.py
python test_documents_routes.py
python test_extractions_routes.py
python test_ingestion_routes.py
python test_all_endpoints.py
```

## Test Files

The test suite includes the following test files:

- `test_all_endpoints.py`: Tests all API endpoints in a single script
- `test_health_routes.py`: Tests the health check endpoint
- `test_documents_routes.py`: Tests document-related endpoints
- `test_extractions_routes.py`: Tests extraction-related endpoints
- `test_ingestion_routes.py`: Tests ingestion-related endpoints
- `run_all_tests.py`: Script to run all test files and generate a consolidated report

## Test Coverage

The test suite covers the following route categories:

### Health Routes
- GET /health

### Document Routes
- GET /api/documents
- GET /api/documents/:id
- GET /api/documents/next/:id
- DELETE /api/documents/:id (disabled by default)

### Processing Routes
- GET /api/documents/:id/file
- POST /api/documents/:id/process
- POST /api/documents/:id/reprocess/:section

### Extraction Routes
- GET /api/extractions
- GET /api/extractions/:id
- GET /api/extractions/document/:id
- GET /api/extractions/:id/csv
- GET /api/extractions/:id/markdown
- GET /api/extractions/:id/json
- PATCH /api/extractions/:id (disabled by default)

### Ingestion Routes
- GET /api/v1/status
- OPTIONS /api/v1/documents
- POST /api/v1/documents (disabled by default)

## Server Requirements

The tests assume the API server is running on `http://localhost:5000`. Make sure your server is running before executing the tests.

## Test Reports

After running the tests, JSON reports will be generated in the same directory:

- `api_test_results.json`: Generated by `test_all_endpoints.py`
- `test_report.json`: Generated by `run_all_tests.py`

## Understanding the Results

The test output uses color coding:

- ðŸŸ¢ Green: Successful tests
- ðŸ”´ Red: Failed tests
- ðŸ”µ Blue: Informational messages
- ðŸŸ¡ Yellow: Warnings

The test results also indicate:

- HTTP status codes
- Response content
- Any validation errors

## Known Issues

Some tests may fail due to:

1. PostgreSQL database connectivity issues (the server logs show ECONNREFUSED errors)
2. Routes returning HTML instead of JSON (some routes may be rendering frontend pages)
3. Mock data mechanisms in the document routes not working for certain endpoints
4. Missing files for document-specific operations

These issues are related to the test environment rather than the modular routes structure itself.

## Troubleshooting

If tests are failing, check:

1. Is the server running on port 5000?
2. Do you have the necessary dependencies installed?
3. Are there any database connectivity issues? (The logs show PostgreSQL connection errors)
4. Are the mock data mechanisms working correctly?

## Adding New Tests

To add a new test file:

1. Create a new Python file with prefix `test_` (e.g., `test_processing_routes.py`)
2. Import the necessary modules (requests, json, sys, colorama)
3. Define test functions for each endpoint
4. Add a main execution block that returns a non-zero exit code on failure

The `run_all_tests.py` script will automatically detect and run any file that follows this naming convention. 